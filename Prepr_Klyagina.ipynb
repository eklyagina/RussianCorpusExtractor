{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Final project <b>\n",
    "    \n",
    "    \n",
    "Last May for my R project, I studied russian verbs (prygnul) and verboids (pryg) on the basis of Russian Corpus. I investigated what pattern can affect the choice of a verboid instead of a verb. I check three parameters: unexpectedness (The hypothesis was that verboids are used more often in the unxpected contexts), being part of a coordinated chain (The hypothesis was that verboids are used more often in the coordinated chains, cf.: 'on pryg i ybezhal') and the year of publication (The hypothesis was that verboids should be used in older texts). The first hypothesis was confirmed, the second one wasn't, but my data concerning the year of publication proved to be not very good because it seems that Russian corpus give a very bad random sample (not random at all concering the year of publication). \n",
    "Thus, for my final python project I decided to write a program that would extract all the examples (from all the search pages) fitting the inquiry so that I could then randomize it.\n",
    "So as an input I give the link (to the any page except for the first one because it has a different default structure), the number of page and the name of the output file.\n",
    "As an output I take the file with three columns: the text of the examples, the info about the auther and the date, the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import pandas as pd \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code of the program for the fixed inquiry to check if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.67s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>info</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>А он прыг на форточку, а там четырнадцатый этаж.</td>\n",
       "      <td>Сергей Шикера. Египетское метро // «Волга», 20...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Она с тумбочки прыг и покорно идет.</td>\n",
       "      <td>Сергей Носов. Фигурные скобки (2015)]</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Через игру научила командам «лежать», «сидеть»...</td>\n",
       "      <td>Диана Злобина. Зачем ученые лис приручили // «...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Девочки уже раздали автографы и явно скучали ―...</td>\n",
       "      <td>Виктор Пелевин. S.N.U.F.F (2011)]</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>― Пупарас Трыг ― мое сердце прыг, ― пробормот...</td>\n",
       "      <td>Виктор Пелевин. S.N.U.F.F (2011)]</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Одинъ разсказываетъ: «Иду я гдѣ-то, а мимо мен...</td>\n",
       "      <td>П. А. Ровинский. Черты из боевой жизни Черного...</td>\n",
       "      <td>1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Благословясь да богу помолясь, а не так как-ни...</td>\n",
       "      <td>М. Е. Салтыков-Щедрин. Господа Головлевы (1875...</td>\n",
       "      <td>1875-1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>все-то у тебя на уме прыг да шмыг!</td>\n",
       "      <td>М. Е. Салтыков-Щедрин. Господа Головлевы (1875...</td>\n",
       "      <td>1875-1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Вот поравнялись мы с телегой… вдруг великан в ...</td>\n",
       "      <td>И. С. Тургенев. Стучит! (1874)]</td>\n",
       "      <td>1874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Иду и вижу, что в коляске подлетает к вашему д...</td>\n",
       "      <td>А. Ф. Писемский. Ваал (1873)]</td>\n",
       "      <td>1873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 texts  \\\n",
       "0    А он прыг на форточку, а там четырнадцатый этаж.    \n",
       "1                 Она с тумбочки прыг и покорно идет.    \n",
       "2    Через игру научила командам «лежать», «сидеть»...   \n",
       "3    Девочки уже раздали автографы и явно скучали ―...   \n",
       "4     ― Пупарас Трыг ― мое сердце прыг, ― пробормот...   \n",
       "..                                                 ...   \n",
       "191  Одинъ разсказываетъ: «Иду я гдѣ-то, а мимо мен...   \n",
       "192  Благословясь да богу помолясь, а не так как-ни...   \n",
       "193                все-то у тебя на уме прыг да шмыг!    \n",
       "194  Вот поравнялись мы с телегой… вдруг великан в ...   \n",
       "195  Иду и вижу, что в коляске подлетает к вашему д...   \n",
       "\n",
       "                                                  info      dates  \n",
       "0    Сергей Шикера. Египетское метро // «Волга», 20...       2016  \n",
       "1               Сергей Носов. Фигурные скобки (2015)]        2015  \n",
       "2    Диана Злобина. Зачем ученые лис приручили // «...       2014  \n",
       "3                   Виктор Пелевин. S.N.U.F.F (2011)]        2011  \n",
       "4                   Виктор Пелевин. S.N.U.F.F (2011)]        2011  \n",
       "..                                                 ...        ...  \n",
       "191  П. А. Ровинский. Черты из боевой жизни Черного...       1880  \n",
       "192  М. Е. Салтыков-Щедрин. Господа Головлевы (1875...  1875-1880  \n",
       "193  М. Е. Салтыков-Щедрин. Господа Головлевы (1875...  1875-1880  \n",
       "194                   И. С. Тургенев. Стучит! (1874)]        1874  \n",
       "195                     А. Ф. Писемский. Ваал (1873)]        1873  \n",
       "\n",
       "[196 rows x 3 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\n",
    "info = []\n",
    "dates = []\n",
    "#search all the pages\n",
    "for page in tqdm(range(3)):\n",
    "    new_examples = []\n",
    "    info_local = []\n",
    "    #open the link\n",
    "    req = urllib.request.Request('https://processing.ruscorpora.ru/search.xml?spp=50&text=lexgramm&level1=0&level2=0&api=1.0&spd=100&sem-mod2=sem&sem-mod2=sem2&sem-mod1=sem&sem-mod1=sem2&env=alpha&nodia=1&parent2=0&sort=i_grtagging&startyear=1800&min2=1&lang=ru&lex1=%D0%BF%D1%80%D1%8B%D0%B3&dpp=50&max2=1&endyear=2019&mode=main&parent1=0&p=' + str(page))\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        html = response.read().decode('utf-8')\n",
    "    #extract the examples\n",
    "    regEx = re.compile('<li>.*?</span> <span class=\"off\"> ', flags= re.DOTALL)\n",
    "    examples = regEx.findall(html)\n",
    "    #delete rubish\n",
    "    regTitle = re.compile(\".*?Все примеры\", re.DOTALL)\n",
    "    regTag = re.compile('<.*?>', re.DOTALL)\n",
    "    for ex in examples:\n",
    "        clean_ex = regTag.sub(\"\", ex)\n",
    "        clean_ex = regTitle.sub(\"\",clean_ex)\n",
    "        clean_ex = clean_ex.replace(\"  \", \" \")\n",
    "        new_examples.append(clean_ex)\n",
    "    #split the example into text and info about the publication\n",
    "    for ex in new_examples:\n",
    "        new_ex = ex.split(\"[\")\n",
    "        text = new_ex[0]\n",
    "        #to be sure that phrases like \"на том [берегу]\" are not parsed like \"info\"\n",
    "        for n in new_ex[1:]:\n",
    "            res = re.search(\"\\d\\d\\d\\d\", n)\n",
    "            if res:\n",
    "            \n",
    "                info.append(n)\n",
    "                #to work with it later\n",
    "                info_local.append(n)\n",
    "            else:\n",
    "                text = new_ex[0] + \"[\"  + n\n",
    "        texts.append(text) \n",
    "    #extract information about the date from the \"info\"\n",
    "    for i in range(len(info_local)):\n",
    "        res = re.search(\"\\d\\d\\d\\d-\\d\\d\\d\\d\", info_local[i])\n",
    "        if not res:\n",
    "            res = re.search(\"\\d\\d\\d\\d\", info_local[i])\n",
    "        dates.append(res.group())\n",
    "#make a table\n",
    "pryg = pd.DataFrame({\n",
    "    \"texts\": texts ,\n",
    "    \"info\": info,\n",
    "    \"dates\": dates,\n",
    "})\n",
    "pryg.to_csv(\"pryg.csv\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the same but as function.\n",
    "(in case I forget how it works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "def RussianCorpusExctractor(number_of_pages, output_file_name, url):\n",
    "    texts = []\n",
    "    info = []\n",
    "    dates = []\n",
    "    for page in tqdm(range(number_of_pages-1)):\n",
    "        new_examples = []\n",
    "        info_local = []\n",
    "        req = urllib.request.Request(url[:-1]+str(page))\n",
    "        with urllib.request.urlopen(req) as response:\n",
    "            html = response.read().decode('utf-8')\n",
    "        regEx = re.compile('<li>.*?</span> <span class=\"off\"> ', flags= re.DOTALL)\n",
    "        examples = regEx.findall(html)\n",
    "        regTitle = re.compile(\".*?Все примеры\", re.DOTALL)\n",
    "        regTag = re.compile('<.*?>', re.DOTALL)\n",
    "        for ex in examples:\n",
    "            clean_ex = regTag.sub(\"\", ex)\n",
    "            clean_ex = regTitle.sub(\"\",clean_ex)\n",
    "            clean_ex = clean_ex.replace(\"  \", \" \")\n",
    "            new_examples.append(clean_ex)\n",
    "        for ex in new_examples:\n",
    "            new_ex = ex.split(\"[\")\n",
    "            text = new_ex[0]\n",
    "            for n in new_ex[1:]:\n",
    "                res = re.search(\"\\d\\d\\d\\d\", n)\n",
    "                if res:\n",
    "                    info.append(n)\n",
    "                    info_local.append(n)\n",
    "                else:\n",
    "                    text = new_ex[0] + \"[\"  + n\n",
    "            texts.append(text)   \n",
    "        for i in range(len(info_local)):\n",
    "            res = re.search(\"\\d\\d\\d\\d-\\d\\d\\d\\d\", info_local[i])\n",
    "            if not res:\n",
    "                res = re.search(\"\\d\\d\\d\\d\", info_local[i])\n",
    "            dates.append(res.group())\n",
    "    data = pd.DataFrame({\n",
    "        \"texts\": texts ,\n",
    "        \"info\": info,\n",
    "        \"dates\": dates,\n",
    "    })\n",
    "    return data.to_csv(output_file_name+\".csv\", encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [02:12<00:00,  4.26s/it]\n"
     ]
    }
   ],
   "source": [
    "RussianCorpusExctractor(32, \"prygnul\", 'https://processing.ruscorpora.ru/search.xml?text=lexgramm&level1=0&level2=0&api=1.0&spd=50&out=normal&sem-mod2=sem&sem-mod2=sem2&sem-mod1=sem&sem-mod1=sem2&env=alpha&nodia=1&mode=main&sort=random&startyear=1800&min2=1&seed=9336&lang=ru&lex1=%22%D0%BF%D1%80%D1%8B%D0%B3%D0%BD%D1%83%D0%BB%22%7C%22%D0%BF%D1%80%D1%8B%D0%B3%D0%BD%D1%83%D0%BB%D0%B0%22%7C%22%D0%BF%D1%80%D1%8B%D0%B3%D0%BD%D1%83%D0%BB%D0%BE%22%7C%22%D0%BF%D1%80%D1%8B%D0%B3%D0%BD%D1%83%D0%BB%D0%B8%22&dpp=50&max2=1&endyear=2019&parent2=0&parent1=0&p=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
